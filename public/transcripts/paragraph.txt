Hey everyone, here's as he outages from NMMIT Karnataka, and today we are super excited to present a project for Hackfish 2025 under the open innovation track. I wish trouble with hearts of record and meetings, lectures or interviews, manually listening, taking notes and searching for key points is very exhausting right. But what if there is a tool that could do the hard work for you? Well, that's exactly what you will think about it, every day we attend meetings, listen to podcasts and watch lectures. But when we need to extract key insights, it's a nightmare. This will be real, listening to an entire recording just to find an important moment, it's a huge waste of time right. Manually some amazing long discussions, super inefficient, skipping through videos and I'm hoping to find key parts, it's very frustrating. So we ask ourselves, what if an A could take care of this? And this is exactly how our A power media processing tool was born. Our tool makes A and video files are achievable, interactive and insightful. Here's a, we swear A, think of this as a super smart subtitle, swear media files. Isn't the speech and turns it into text with high accuracy, even with background nicer multiple accents. Where the sentiment analysis, it detects emotions in speech. Was the speaker happy, neutral, upset? This is great for analyzing customer calls, debates or interviews. Space in there automatically detects names, places and key topics. Let's save someone mentions NASA or a, or let's say Elon Musk. It highlights them instantly, like it's useful for research and organization purposes. But that's not all, they packed this tool with interactive features. We can search any key word or jump into an important moment. Just type in a word like budget in a meeting and that's it. It takes you there instantly. We also have clickable timestamps. You must have seen this feature in YouTube, where every sentence in a transcript has a timestamp. Click on it and an audio or video jumps it at exact moment. Also, we do not have to go through the entire file. The AI picks up the key points and gives you a quick summary. Whether it's a podcast or an online author business meeting, the tool works perfectly with both. If multiple people are talking, the AI identifies different voices and labels who said what? Expeeker one and speaker two. You also have a special unique feature called the mind map. We're instead of reading a wall of text. We basically get a word to the road map of the entire conversation, making it easier to understand key topics and connectors. Now let's discuss the text tag. We'll be using XDS and TypeScript for a smooth user interface with no JS and Express for handling the backend. We are also trying to run this as locally as possible. Like we're using open as we were local model for transcription. Video for sentiment analysis and space in it, just like I said before. And as for database for storing the bookmarks and timestamps, we'll be using PostgreSQL. And hopefully scale it on DB. Video processing will be using GIFF Mac. We do JS and wave software JS for seamless payback. This study is designed for anyone who deals with audio or video content. In a corporation, this can be used to extract key decisions from long meetings. Students could use this as a summer's literature and study smart. A legal team could generate automatic transcripts for case studies. Content creators could repurpose the best movements. A support team could analyze customer interactions for a better service. We believe that I can transform the process audio and video content, making it more accessible, interactive and intelligent. We're hoping that this could be a great tool that could help a lot of people. And that's a wrap up for a short video of expanding our project. Hopefully we'll see you in HackFest. Goodbye for now.